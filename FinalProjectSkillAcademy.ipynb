{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamzaharmanhusni/ProjectSkillAcademyPro/blob/main/FinalProjectSkillAcademy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Project: Portfolio - Final Project"
      ],
      "metadata": {
        "id": "vmrd_UTEEb6z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5120b06-0abf-49e3-b54d-db8afa9eda01"
      },
      "source": [
        "**Instructions for Students:**\n",
        "\n",
        "Please carefully follow these steps to complete and submit your assignment:\n",
        "\n",
        "1. **Completing the Assignment**: You are required to work on and complete all tasks in the provided assignment. Be disciplined and ensure that you thoroughly engage with each task.\n",
        "   \n",
        "2. **Creating a Google Drive Folder**: If you don't previously have a folder for collecting assignments, you must create a new folder in your Google Drive. This will be a repository for all your completed assignment files, helping you keep your work organized and easy to access.\n",
        "   \n",
        "3. **Uploading Completed Assignment**: Upon completion of your assignment, make sure to upload all necessary files, involving codes, reports, and related documents into the created Google Drive folder. Save this link in the 'Student Identity' section and also provide it as the last parameter in the `submit` function that has been provided.\n",
        "   \n",
        "4. **Sharing Folder Link**: You're required to share the link to your assignment Google Drive folder. This is crucial for the submission and evaluation of your assignment.\n",
        "   \n",
        "5. **Setting Permission toPublic**: Please make sure your **Google Drive folder is set to public**. This allows your instructor to access your solutions and assess your work correctly.\n",
        "\n",
        "Adhering to these procedures will facilitate a smooth assignment process for you and the reviewers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eca56111-19cb-46c0-a77b-11bd18c55673"
      },
      "source": [
        "**Description:**\n",
        "\n",
        "Welcome to your final portfolio project assignment for AI Bootcamp. This is your chance to put all the skills and knowledge you've learned throughout the bootcamp into action by creating real-world AI application.\n",
        "\n",
        "You have the freedom to create any application or model, be it text-based or image-based or even voice-based or multimodal.\n",
        "\n",
        "To get you started, here are some ideas:\n",
        "\n",
        "1. **Sentiment Analysis Application:** Develop an application that can determine sentiment (positive, negative, neutral) from text data like reviews or social media posts. You can use Natural Language Processing (NLP) libraries like NLTK or TextBlob, or more advanced pre-trained models from transformers library by Hugging Face, for your sentiment analysis model.\n",
        "\n",
        "2. **Chatbot:** Design a chatbot serving a specific purpose such as customer service for a certain industry, a personal fitness coach, or a study helper. Libraries like ChatterBot or Dialogflow can assist in designing conversational agents.\n",
        "\n",
        "3. **Predictive Text Application:** Develop a model that suggests the next word or sentence similar to predictive text on smartphone keyboards. You could use the transformers library by Hugging Face, which includes pre-trained models like GPT-2.\n",
        "\n",
        "4. **Image Classification Application:** Create a model to distinguish between different types of flowers or fruits. For this type of image classification task, pre-trained models like ResNet or VGG from PyTorch or TensorFlow can be utilized.\n",
        "\n",
        "5. **News Article Classifier:** Develop a text classification model that categorizes news articles into predefined categories. NLTK, SpaCy, and sklearn are valuable libraries for text pre-processing, feature extraction, and building classification models.\n",
        "\n",
        "6. **Recommendation System:** Create a simplified recommendation system. For instance, a book or movie recommender based on user preferences. Python's Surprise library can assist in building effective recommendation systems.\n",
        "\n",
        "7. **Plant Disease Detection:** Develop a model to identify diseases in plants using leaf images. This project requires a good understanding of convolutional neural networks (CNNs) and image processing. PyTorch, TensorFlow, and OpenCV are all great tools to use.\n",
        "\n",
        "8. **Facial Expression Recognition:** Develop a model to classify human facial expressions. This involves complex feature extraction and classification algorithms. You might want to leverage deep learning libraries like TensorFlow or PyTorch, along with OpenCV for processing facial images.\n",
        "\n",
        "9. **Chest X-Ray Interpretation:** Develop a model to detect abnormalities in chest X-ray images. This task may require understanding of specific features in such images. Again, TensorFlow and PyTorch for deep learning, and libraries like SciKit-Image or PIL for image processing, could be of use.\n",
        "\n",
        "10. **Food Classification:** Develop a model to classify a variety of foods such as local Indonesian food. Pre-trained models like ResNet or VGG from PyTorch or TensorFlow can be a good starting point.\n",
        "\n",
        "11. **Traffic Sign Recognition:** Design a model to recognize different traffic signs. This project has real-world applicability in self-driving car technology. Once more, you might utilize PyTorch or TensorFlow for the deep learning aspect, and OpenCV for image processing tasks.\n",
        "\n",
        "**Submission:**\n",
        "\n",
        "Please upload both your model and application to Huggingface or your own Github account for submission.\n",
        "\n",
        "**Presentation:**\n",
        "\n",
        "You are required to create a presentation to showcase your project, including the following details:\n",
        "\n",
        "- The objective of your model.\n",
        "- A comprehensive description of your model.\n",
        "- The specific metrics used to measure your model's effectiveness.\n",
        "- A brief overview of the dataset used, including its source, pre-processing steps, and any insights.\n",
        "- An explanation of the methodology used in developing the model.\n",
        "- A discussion on challenges faced, how they were handled, and your learnings from those.\n",
        "- Suggestions for potential future improvements to the model.\n",
        "- A functioning link to a demo of your model in action.\n",
        "\n",
        "**Grading:**\n",
        "\n",
        "Submissions will be manually graded, with a select few given the opportunity to present their projects in front of a panel of judges. This will provide valuable feedback, further enhancing your project and expanding your knowledge base.\n",
        "\n",
        "Remember, consistent practice is the key to mastering these concepts. Apply your knowledge, ask questions when in doubt, and above all, enjoy the process. Best of luck to you all!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "213a611a-c434-4894-ba35-689963ee5274"
      },
      "outputs": [],
      "source": [
        "# @title #### Student Identity\n",
        "student_id = \"REAJGDG4\" # @param {type:\"string\"}\n",
        "name = \"Hamzah Arman Husni\" # @param {type:\"string\"}\n",
        "drive_link = \"https://colab.research.google.com/drive/1XiJGQQLIAlSiHT_AN2cg-sA47GOHW84d?authuser=1\"  # @param {type:\"string\"}\n",
        "assignment_id = \"00_portfolio_project\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c97aef3-b747-49f7-99e0-4086c03e4200"
      },
      "source": [
        "## Installation and Import `rggrader` Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36c07e23-0280-467f-b0d2-44d966253bb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c95ae252-86a6-4d86-b66b-238a36fc42d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rggrader\n",
            "  Downloading rggrader-0.1.6-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from rggrader) (2.31.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from rggrader) (1.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rggrader) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->rggrader) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->rggrader) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->rggrader) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->rggrader) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->rggrader) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->rggrader) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->rggrader) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->rggrader) (1.16.0)\n",
            "Installing collected packages: rggrader\n",
            "Successfully installed rggrader-0.1.6\n"
          ]
        }
      ],
      "source": [
        "%pip install rggrader\n",
        "from rggrader import submit_image\n",
        "from rggrader import submit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4af3420-ff0e-472b-8b44-7a495ddf76c3"
      },
      "source": [
        "## Working Space"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1gmNJG2v0U8",
        "outputId": "78f89aa0-bd2b-4fa3-cded-9d21b20c5df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --quiet tensorflow-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgiqXWQrr0qu",
        "outputId": "9cf56a94-8bd5-444c-e61c-42fc5107782b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.8/286.8 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqAAvfBEyqnB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994db63f-bb11-4ab5-9485-cbc7b1f881cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-52a7ec50-a58d-135a-c56b-382b4feff26e)\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "id": "KLRXxdULzO86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9dc2c1c-2ef1-49f0-af68-6677a986f2ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 39 (delta 8), reused 5 (delta 5), pack-reused 25\u001b[K\n",
            "Receiving objects: 100% (39/39), 177.08 MiB | 15.39 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Updating files: 100% (13/13), done.\n",
            "PubMed_200k_RCT\t\t\t\t       PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign  README.md\n",
            "PubMed_20k_RCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get The Data\n",
        "\n",
        "The authors of the paper have generously made the data they utilized for their research publicly accessible and free of charge, providing it in the form of .txt files on GitHub.\n",
        "\n",
        "We can copy them to our local directory using git clone https://github.com/Franck-Dernoncourt/pubmed-rct."
      ],
      "metadata": {
        "id": "RZ9f8NYJzVbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what files are in the PubMed_20K dataset\n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign"
      ],
      "metadata": {
        "id": "tTsgC_aez7MM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70911304-03b7-419d-b39f-dd854d2bb9a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start by using the 20k dataset\n",
        "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "metadata": {
        "id": "_i1BRW5jFVRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check all of the filenames in the target directory\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "metadata": {
        "id": "rndBOxri0DAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d9dae0-135f-42b8-8622-fe0a19ec3b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pengolahan data dengan 200k dataset\n",
        "\n",
        "# import zipfile\n",
        "\n",
        "# zip_file_path = \"pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign/train.zip\"\n",
        "# extract_to_directory = \"pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign/\"\n",
        "\n",
        "# # Open the zip file\n",
        "# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "#     # Extract all the contents into the specified directory\n",
        "#     zip_ref.extractall(extract_to_directory)\n",
        "\n",
        "# print(\"Extraction completed successfully.\")"
      ],
      "metadata": {
        "id": "wTiAcqCi50Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Data"
      ],
      "metadata": {
        "id": "mUlSI7pg0ETq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the text\n",
        "with open(data_dir + \"train.txt\", \"r\") as f:\n",
        "    train_lines = f.readlines()\n",
        "\n",
        "train_lines[:50]"
      ],
      "metadata": {
        "id": "KWJk5FFi0NHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db1e8276-1d3d-4dfb-ca40-816b27016d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n',\n",
              " 'METHODS\\tAttentional biases for high caloric foods were measured by eye tracking during a visual probe task with pictorial food and neutral stimuli .\\n',\n",
              " 'METHODS\\tSelf-reported emotional eating was assessed with the Dutch Eating Behavior Questionnaire ( DEBQ ) and ad libitum food intake was tested by a disguised food offer .\\n',\n",
              " 'RESULTS\\tHierarchical multivariate regression modeling showed that self-reported emotional eating did not account for changes in attention allocation for food or food intake in either condition .\\n',\n",
              " 'RESULTS\\tYet , attention maintenance on food cues was significantly related to increased intake specifically in the neutral condition , but not in the sad mood condition .\\n',\n",
              " 'CONCLUSIONS\\tThe current findings show that self-reported emotional eating ( based on the DEBQ ) might not validly predict who overeats when sad , at least not in a laboratory setting with healthy women .\\n',\n",
              " 'CONCLUSIONS\\tResults further suggest that attention maintenance on food relates to eating motivation when in a neutral affective state , and might therefore be a cognitive mechanism contributing to increased food intake in general , but maybe not during sad mood .\\n',\n",
              " '\\n',\n",
              " '###25165090\\n',\n",
              " 'BACKGROUND\\tAlthough working smoke alarms halve deaths in residential fires , many households do not keep alarms operational .\\n',\n",
              " 'BACKGROUND\\tWe tested whether theory-based education increases alarm operability .\\n',\n",
              " 'METHODS\\tRandomised multiarm trial , with a single arm randomly selected for use each day , in low-income neighbourhoods in Maryland , USA .\\n',\n",
              " \"METHODS\\tIntervention arms : ( @ ) Full Education combining a health belief module with a social-cognitive theory module that provided hands-on practice installing alarm batteries and using the alarm 's hush button ; ( @ ) Hands-on Practice social-cognitive module supplemented by typical fire department education ; ( @ ) Current Norm receiving typical fire department education only .\\n\",\n",
              " 'METHODS\\tFour hundred and thirty-six homes recruited through churches or by knocking on doors in @-@ .\\n',\n",
              " 'METHODS\\tFollow-up visits checked alarm operability in @ homes ( @ % ) @-@ @ years after installation .\\n',\n",
              " 'METHODS\\tnumber of homes with working alarms defined as alarms with working batteries or hard-wired and number of working alarms per home .\\n',\n",
              " 'METHODS\\tRegressions controlled for alarm status preintervention ; demographics and beliefs about fire risks and alarm effectiveness .\\n',\n",
              " 'RESULTS\\tHomes in the Full Education and Practice arms were more likely to have a functioning smoke alarm at follow-up ( OR = @ , @ % CI @ to @ ) and had an average of @ more working alarms per home ( @ % CI @ to @ ) .\\n',\n",
              " 'RESULTS\\tWorking alarms per home rose @ % .\\n',\n",
              " 'RESULTS\\tFull Education and Practice had similar effectiveness ( p = @ on both outcome measures ) .\\n',\n",
              " 'CONCLUSIONS\\tWithout exceeding typical fire department installation time , installers can achieve greater smoke alarm operability .\\n',\n",
              " 'CONCLUSIONS\\tHands-on practice is key .\\n',\n",
              " 'CONCLUSIONS\\tTwo years after installation , for every three homes that received hands-on practice , one had an additional working alarm .\\n',\n",
              " 'BACKGROUND\\thttp://www.clinicaltrials.gov number NCT@ .\\n',\n",
              " '\\n',\n",
              " '###24633056\\n',\n",
              " 'OBJECTIVE\\tTo evaluate the performance ( efficacy , safety and acceptability ) of a new micro-adherent absorbent dressing ( UrgoClean ) compared with a hydrofiber dressing ( Aquacel ) in the local management of venous leg ulcers , in the debridement stage .\\n',\n",
              " 'METHODS\\tA non-inferiority European randomised controlled clinical trial ( RCT ) was conducted in @ centres , on patients presenting with venous or predominantly venous , mixed aetiology leg ulcers at their sloughy stage ( with more than @ % of the wound bed covered with slough at baseline ) .\\n',\n",
              " 'METHODS\\tPatients were followed over a @-week period and assessed weekly .\\n',\n",
              " 'METHODS\\tThe primary judgement criteria was the relative regression of the wound surface area after the @-week treatment period .\\n',\n",
              " 'METHODS\\tSecondary endpoints were the relative reduction of sloughy tissue and the percentage of patients presenting with a debrided wound .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to read the lines of a document\n",
        "def get_lines(filename):\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "metadata": {
        "id": "3dXZFx46FhoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  input_lines = get_lines(filename) # get all lines from filename\n",
        "  abstract_lines = \"\" # create an empty abstract\n",
        "  abstract_samples = [] # create an empty list of abstracts\n",
        "\n",
        "  # Loop through each line in target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"): # check to see if line is an ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" # reset abstract string\n",
        "    elif line.isspace(): # check to see if line is a new line\n",
        "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
        "\n",
        "      # Iterate through each line in abstract and count them at the same time\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # create empty dict to store data from line\n",
        "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
        "        line_data[\"target\"] = target_text_split[0] # get target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
        "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
        "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
        "\n",
        "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
        "      abstract_lines += line\n",
        "\n",
        "  return abstract_samples"
      ],
      "metadata": {
        "id": "0ZHr53Ww1X0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data from file and preprocess it\n",
        "\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") # dev is another name for validation set\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "len(train_samples), len(val_samples), len(test_samples)"
      ],
      "metadata": {
        "id": "AMDRpQ8y1bqB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04de381-bb56-4d98-a6d6-d5083dcbe7dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first abstract of our training data\n",
        "train_samples[:15]"
      ],
      "metadata": {
        "id": "DBpI7RR4125E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199de7c1-ccfa-4fca-a523-241fee6297a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'line_number': 8,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'line_number': 9,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              "  'line_number': 10,\n",
              "  'total_lines': 11},\n",
              " {'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'line_number': 11,\n",
              "  'total_lines': 11},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 10},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 10},\n",
              " {'target': 'OBJECTIVE',\n",
              "  'text': 'the aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 10}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head(15)"
      ],
      "metadata": {
        "id": "GB7q_VdW16-_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "8ad3e58a-6da9-41b4-98a7-f16dd40cff5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         target                                               text  \\\n",
              "0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
              "1       METHODS  a total of @ patients with primary knee oa wer...   \n",
              "2       METHODS  outcome measures included pain reduction and i...   \n",
              "3       METHODS  pain was assessed using the visual analog pain...   \n",
              "4       METHODS  secondary outcome measures included the wester...   \n",
              "5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n",
              "6       RESULTS  there was a clinically relevant reduction in t...   \n",
              "7       RESULTS  the mean difference between treatment arms ( @...   \n",
              "8       RESULTS  further , there was a clinically relevant redu...   \n",
              "9       RESULTS  these differences remained significant at @ we...   \n",
              "10      RESULTS  the outcome measures in rheumatology clinical ...   \n",
              "11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
              "12   BACKGROUND  emotional eating is associated with overeating...   \n",
              "13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n",
              "14    OBJECTIVE  the aim of this study was to test if attention...   \n",
              "\n",
              "    line_number  total_lines  \n",
              "0             0           11  \n",
              "1             1           11  \n",
              "2             2           11  \n",
              "3             3           11  \n",
              "4             4           11  \n",
              "5             5           11  \n",
              "6             6           11  \n",
              "7             7           11  \n",
              "8             8           11  \n",
              "9             9           11  \n",
              "10           10           11  \n",
              "11           11           11  \n",
              "12            0           10  \n",
              "13            1           10  \n",
              "14            2           10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-224faba7-892c-4881-b344-d2300cd07c35\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>the aim of this study was to test if attention...</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-224faba7-892c-4881-b344-d2300cd07c35')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-224faba7-892c-4881-b344-d2300cd07c35 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-224faba7-892c-4881-b344-d2300cd07c35');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-559b426e-7d15-407a-8811-8a9d0581a53a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-559b426e-7d15-407a-8811-8a9d0581a53a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-559b426e-7d15-407a-8811-8a9d0581a53a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of labels in training data\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "id": "lvDSJ-BN1-uN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "514b4af1-a314-4b21-f0a8-09566d337853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess"
      ],
      "metadata": {
        "id": "SDLfbO3z7TUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "STOPWORDS = stopwords.words(\"english\")\n",
        "print (STOPWORDS[:5])\n",
        "\n",
        "def preprocess(text, stopwords=STOPWORDS):\n",
        "    \"\"\"Conditional preprocessing on our text unique to our task.\"\"\"\n",
        "    # Lower\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove stopwords\n",
        "    pattern = re.compile(r\"\\b(\" + r\"|\".join(stopwords) + r\")\\b\\s*\")\n",
        "    text = pattern.sub(\"\", text)\n",
        "\n",
        "    # Remove words in paranthesis\n",
        "    text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
        "\n",
        "    # Spacing and filters\n",
        "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
        "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text) # remove non alphanumeric chars\n",
        "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# Apply to dataframe\n",
        "preprocessed_train_df = train_df.copy()\n",
        "preprocessed_train_df.text = preprocessed_train_df.text.apply(preprocess)\n",
        "print (f\"{train_df.text.values[0]}\\n\\n{preprocessed_train_df.text.values[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YismOsH7VME",
        "outputId": "11992f01-2c5d-46f8-a562-25c2104be766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we']\n",
            "to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .\n",
            "\n",
            "investigate efficacy weeks daily low dose oral prednisolone improving pain mobility systemic low grade inflammation short term whether effect would sustained weeks older adults moderate severe knee osteoarthritis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlcMHY8HGaf4",
        "outputId": "553f2e1d-8b9d-4fe6-9a15-d9a873bfb0f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "# Initialize WordNetLemmatizer outside the function for efficiency\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    # Map POS tags from Penn Treebank POS tags to WordNet POS tags\n",
        "    def get_wordnet_pos(tag):\n",
        "        if tag.startswith('J'):\n",
        "            return wn.ADJ\n",
        "        elif tag.startswith('V'):\n",
        "            return wn.VERB\n",
        "        elif tag.startswith('N'):\n",
        "            return wn.NOUN\n",
        "        elif tag.startswith('R'):\n",
        "            return wn.ADV\n",
        "        else:\n",
        "            return wn.NOUN  # Default to noun if no match\n",
        "\n",
        "    # Tokenize text and get POS tags\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "    # Lemmatize tokens using WordNetLemmatizer with appropriate POS tags\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(pos_tag)) for word, pos_tag in pos_tags]\n",
        "\n",
        "    # Join lemmatized tokens back into a single string\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "# Apply lemmatization function to 'text' column of preprocessed_df\n",
        "preprocessed_train_df['text'] = preprocessed_train_df['text'].apply(lemmatize_text)\n"
      ],
      "metadata": {
        "id": "zY_BdRLLAO4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_train_df.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "FUupfxY7HaSg",
        "outputId": "82297388-8b88-40fb-c8ce-500fe38ffb39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         target                                               text  \\\n",
              "0     OBJECTIVE  investigate efficacy week daily low dose oral ...   \n",
              "1       METHODS  total patient primary knee oa randomize receiv...   \n",
              "2       METHODS  outcome measure include pain reduction improve...   \n",
              "3       METHODS           pain assess use visual analog pain scale   \n",
              "4       METHODS  secondary outcome measure include western onta...   \n",
              "5       METHODS  serum level interleukin il tumor necrosis fact...   \n",
              "6       RESULTS  clinically relevant reduction intervention gro...   \n",
              "7       RESULTS  mean difference treatment arm p p p p respecti...   \n",
              "8       RESULTS  clinically relevant reduction serum level il i...   \n",
              "9       RESULTS                 difference remain significant week   \n",
              "10      RESULTS  outcome measure rheumatology clinical trial os...   \n",
              "11  CONCLUSIONS  low dose oral prednisolone short term longer s...   \n",
              "12   BACKGROUND  emotional eating associate overeat development...   \n",
              "13   BACKGROUND  yet empirical evidence individual difference e...   \n",
              "14    OBJECTIVE  aim study test attention bias food moderate ef...   \n",
              "15    OBJECTIVE  expect emotional eating predictive elevate att...   \n",
              "16      METHODS  participant randomly assign one two experiment...   \n",
              "17      METHODS  attentional bias high caloric food measure eye...   \n",
              "18      METHODS  self report emotional eating assess dutch eati...   \n",
              "19      RESULTS  hierarchical multivariate regression modeling ...   \n",
              "\n",
              "    line_number  total_lines  \n",
              "0             0           11  \n",
              "1             1           11  \n",
              "2             2           11  \n",
              "3             3           11  \n",
              "4             4           11  \n",
              "5             5           11  \n",
              "6             6           11  \n",
              "7             7           11  \n",
              "8             8           11  \n",
              "9             9           11  \n",
              "10           10           11  \n",
              "11           11           11  \n",
              "12            0           10  \n",
              "13            1           10  \n",
              "14            2           10  \n",
              "15            3           10  \n",
              "16            4           10  \n",
              "17            5           10  \n",
              "18            6           10  \n",
              "19            7           10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4eac6457-6785-4b53-a87b-c9f1f7838e94\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>investigate efficacy week daily low dose oral ...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>total patient primary knee oa randomize receiv...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measure include pain reduction improve...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain assess use visual analog pain scale</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measure include western onta...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum level interleukin il tumor necrosis fact...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>clinically relevant reduction intervention gro...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>mean difference treatment arm p p p p respecti...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>clinically relevant reduction serum level il i...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>difference remain significant week</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>outcome measure rheumatology clinical trial os...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low dose oral prednisolone short term longer s...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating associate overeat development...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet empirical evidence individual difference e...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>aim study test attention bias food moderate ef...</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>expect emotional eating predictive elevate att...</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>participant randomly assign one two experiment...</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>attentional bias high caloric food measure eye...</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>self report emotional eating assess dutch eati...</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>hierarchical multivariate regression modeling ...</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4eac6457-6785-4b53-a87b-c9f1f7838e94')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4eac6457-6785-4b53-a87b-c9f1f7838e94 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4eac6457-6785-4b53-a87b-c9f1f7838e94');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-16255a34-43a0-443c-937f-b2ea8fc9ba1c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-16255a34-43a0-443c-937f-b2ea8fc9ba1c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-16255a34-43a0-443c-937f-b2ea8fc9ba1c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "preprocessed_train_df"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One Hot Encode"
      ],
      "metadata": {
        "id": "QVzb9pFPASjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data category one-hot-encoding\n",
        "target = pd.get_dummies(preprocessed_train_df.target)\n",
        "df_target = pd.concat([preprocessed_train_df, target], axis=1)\n",
        "df_target = df_target.drop(columns='target')\n",
        "df_target.drop(columns=['line_number', 'total_lines'], inplace=True)\n",
        "df_target.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ptQefdVHAUNJ",
        "outputId": "e995766b-eefb-4183-e1f7-8baddcf65aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  BACKGROUND  CONCLUSIONS  \\\n",
              "0  investigate efficacy week daily low dose oral ...           0            0   \n",
              "1  total patient primary knee oa randomize receiv...           0            0   \n",
              "2  outcome measure include pain reduction improve...           0            0   \n",
              "3           pain assess use visual analog pain scale           0            0   \n",
              "4  secondary outcome measure include western onta...           0            0   \n",
              "5  serum level interleukin il tumor necrosis fact...           0            0   \n",
              "6  clinically relevant reduction intervention gro...           0            0   \n",
              "7  mean difference treatment arm p p p p respecti...           0            0   \n",
              "8  clinically relevant reduction serum level il i...           0            0   \n",
              "9                 difference remain significant week           0            0   \n",
              "\n",
              "   METHODS  OBJECTIVE  RESULTS  \n",
              "0        0          1        0  \n",
              "1        1          0        0  \n",
              "2        1          0        0  \n",
              "3        1          0        0  \n",
              "4        1          0        0  \n",
              "5        1          0        0  \n",
              "6        0          0        1  \n",
              "7        0          0        1  \n",
              "8        0          0        1  \n",
              "9        0          0        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6fd4fa40-8113-4e10-af11-6b3e029d5c47\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>BACKGROUND</th>\n",
              "      <th>CONCLUSIONS</th>\n",
              "      <th>METHODS</th>\n",
              "      <th>OBJECTIVE</th>\n",
              "      <th>RESULTS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>investigate efficacy week daily low dose oral ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>total patient primary knee oa randomize receiv...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>outcome measure include pain reduction improve...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pain assess use visual analog pain scale</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>secondary outcome measure include western onta...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>serum level interleukin il tumor necrosis fact...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>clinically relevant reduction intervention gro...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>mean difference treatment arm p p p p respecti...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>clinically relevant reduction serum level il i...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>difference remain significant week</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fd4fa40-8113-4e10-af11-6b3e029d5c47')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6fd4fa40-8113-4e10-af11-6b3e029d5c47 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6fd4fa40-8113-4e10-af11-6b3e029d5c47');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-efd918bc-b0cd-4597-a2f5-a1840afd44cb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-efd918bc-b0cd-4597-a2f5-a1840afd44cb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-efd918bc-b0cd-4597-a2f5-a1840afd44cb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_target"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change dataframe value to numpy array\n",
        "text = df_target['text'].values\n",
        "train_labels_one_hot = df_target[['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS']].values\n",
        "train_labels_one_hot\n"
      ],
      "metadata": {
        "id": "UATVWNkhAVws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c287cd28-e9d4-4cb8-8c37-9f3f505a3a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 0],\n",
              "       [0, 0, 1, 0, 0],\n",
              "       [0, 0, 1, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, 0, 1],\n",
              "       [0, 1, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation and Test One Hot Code\n"
      ],
      "metadata": {
        "id": "4Qw1WRnq8H5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Create an instance of OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Fit the OneHotEncoder to the training labels\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df['target'].to_numpy().reshape(-1, 1))\n",
        "# Transform the validation and test labels using the fitted OneHotEncoder\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df['target'].to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df['target'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Now you can use the transformed labels\n",
        "print(train_labels_one_hot)\n",
        "print(val_labels_one_hot)\n",
        "print(test_labels_one_hot)\n"
      ],
      "metadata": {
        "id": "n3rXb-g42mnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87c7cb8d-ce5f-4075-b7aa-1c6c787a54c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]]\n",
            "[[1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " ...\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]]\n",
            "[[1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " ...\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label Encoder"
      ],
      "metadata": {
        "id": "YDnR0cFFZDrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "train_label_encoded = label_encoder.fit_transform(train_df['target'].to_numpy())\n",
        "val_label_encoded = label_encoder.transform(val_df['target'].to_numpy())\n",
        "test_label_encoded = label_encoder.transform(test_df['target'].to_numpy())\n",
        "\n",
        "train_label_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezgVqJ3LZFYP",
        "outputId": "0acac840-d0cc-45f4-f836-4595da6979f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "num_classes, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XjMw-M9ZHhw",
        "outputId": "84e67182-19ab-409d-e9e0-d24d87d862f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,\n",
              " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_result(y_true, y_pred):\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "  model_results = {\n",
        "      'accurecy': accuracy,\n",
        "      'precision': model_precision,\n",
        "      'recall': model_recall,\n",
        "      'f1-score': model_f1,\n",
        "  }\n",
        "\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "p0qGlSrvz2n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the PubMed 200k RCT paper states the vocabulary size of the PubMed 20k dataset as 68,000. So we'll use that as our max_tokens parameter."
      ],
      "metadata": {
        "id": "5CD3zey3hjRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = preprocessed_train_df['text'].tolist()\n",
        "val_sentences = val_df['text'].tolist()\n",
        "test_sentences = test_df['text'].tolist()\n",
        "\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDShPRkpGekk",
        "outputId": "592fbf03-2f85-4038-f90b-d0334a603e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization, Embedding\n",
        "\n",
        "\n",
        "max_vocab_length = 68000\n",
        "max_length = 55\n",
        "\n",
        "text_vectorizer = TextVectorization(\n",
        "    max_tokens=max_vocab_length,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=max_length,\n",
        ")"
      ],
      "metadata": {
        "id": "OHOqpoEOFXJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_length = 68000\n",
        "max_length = 55\n",
        "\n",
        "text_vectorizer = TextVectorization(\n",
        "    max_tokens=max_vocab_length,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "\n",
        "text_vectorizer.adapt(train_sentences)\n",
        "\n",
        "# How many words in our training vocabulary?\n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in vocabulary: {len(rct_20k_text_vocab)}\"),\n",
        "print(f\"Most common words in the vocabulary: {rct_20k_text_vocab[:5]}\")\n",
        "print(f\"Least common words in the vocabulary: {rct_20k_text_vocab[-5:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwWXPdrSFbQx",
        "outputId": "95eb6e05-ba3e-4327-8a28-be0753b0b683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7ee373b3b130> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7ee373b3b130>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7ee373b3b130> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7ee373b3b130>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Number of words in vocabulary: 39204\n",
            "Most common words in the vocabulary: ['', '[UNK]', 'group', 'patient', 'study']\n",
            "Least common words in the vocabulary: ['aap', 'aae', 'aado', 'aachener', 'aachen']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = Embedding(\n",
        "    input_dim = len(rct_20k_text_vocab),\n",
        "    output_dim = 128,\n",
        "    name='token_embedding'\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "F0zGcOTMFeCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# List of Sentence"
      ],
      "metadata": {
        "id": "k4ameFa-GdBf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "P9Qkt6rmHpgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Turn our data into TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sfoYXZeBi8Z",
        "outputId": "b7d20025-2118-41dd-a187-f15adf3b0a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the TensorSliceDataset's and turn them into prefetched batches\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoC4LhqgHsKt",
        "outputId": "1630ea63-1d06-4389-da17-707b47988f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing our data for deep learning models"
      ],
      "metadata": {
        "id": "aiVJNW9q4cLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Download pretrained TensorFlow Hub USE\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")\n",
        "# Define feature extractor model using TF Hub layer\n",
        "inputs = layers.Input(shape=[], dtype=tf.string)\n",
        "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and create embedding\n",
        "x = layers.Dense(512, activation=\"relu\")(pretrained_embedding) # add a fully connected layer on top of the embedding\n",
        "x = layers.Dense(256, activation = \"relu\")(x)\n",
        "x  = layers.Dense(128, activation = \"relu\")(x)\n",
        "# Note: you could add more layers here if you wanted to\n",
        "outputs = layers.Dense(5, activation=\"softmax\")(x) # create the output layer\n",
        "model = tf.keras.Model(inputs=inputs,\n",
        "                        outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "# Get a summary of the model\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wn4B8QbQhvA",
        "outputId": "f031e0a3-32e6-44ba-972c-7159dc8b0180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None,)]                 0         \n",
            "                                                                 \n",
            " universal_sentence_encoder  (None, 512)               256797824 \n",
            "  (KerasLayer)                                                   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 257225349 (981.24 MB)\n",
            "Trainable params: 427525 (1.63 MB)\n",
            "Non-trainable params: 256797824 (979.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a learning rate reduction callback\n",
        "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    factor=0.2,           # Factor by which the learning rate will be reduced\n",
        "    patience=3,           # Number of epochs with no improvement after which learning rate will be reduced\n",
        "    min_lr=0.000003,        # Lower bound on the learning rate\n",
        "    verbose=1             # Print a message if the learning rate is reduced\n",
        ")\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor = 'val_loss',  # Monitor validation loss\n",
        "    patience=5,         # Number of epochs with no improvement after which training will be stopped\n",
        "    restore_best_weights=True  # Restore model weights to the epoch with the best validation loss\n",
        ")"
      ],
      "metadata": {
        "id": "xRDNchkUDCks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with both callbacks\n",
        "history = model.fit(train_dataset, epochs=20,\n",
        "                    validation_data=valid_dataset,\n",
        "                    verbose=1,\n",
        "                    callbacks=[reduce_lr_callback, early_stopping_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkvCfW8MKkSJ",
        "outputId": "1a5c1e89-a498-4b8f-adc2-3bec8658161a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "5627/5627 [==============================] - 96s 15ms/step - loss: 0.8597 - accuracy: 0.6675 - val_loss: 0.8277 - val_accuracy: 0.6762 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "5627/5627 [==============================] - 83s 15ms/step - loss: 0.7559 - accuracy: 0.7104 - val_loss: 0.8560 - val_accuracy: 0.6738 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "5627/5627 [==============================] - 76s 14ms/step - loss: 0.6892 - accuracy: 0.7380 - val_loss: 0.8812 - val_accuracy: 0.6765 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "5627/5627 [==============================] - ETA: 0s - loss: 0.6262 - accuracy: 0.7632\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "5627/5627 [==============================] - 104s 18ms/step - loss: 0.6262 - accuracy: 0.7632 - val_loss: 0.9630 - val_accuracy: 0.6692 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "5627/5627 [==============================] - 88s 16ms/step - loss: 0.5139 - accuracy: 0.8054 - val_loss: 1.0729 - val_accuracy: 0.6789 - lr: 2.0000e-04\n",
            "Epoch 6/20\n",
            "5627/5627 [==============================] - 78s 14ms/step - loss: 0.4620 - accuracy: 0.8265 - val_loss: 1.1597 - val_accuracy: 0.6747 - lr: 2.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "vvbk9ER-M0KF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hVCexYjHMr6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc09f922-e849-4875-db25-91d99f2512f2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link download model : https://drive.google.com/drive/folders/1nd87k60AtMgh_jBBPXxm3ELNER2PjUV4?usp=drive_link"
      ],
      "metadata": {
        "id": "6ITGN3aPPEJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Skimlit_UniversalModel')"
      ],
      "metadata": {
        "id": "PnzUT-JA8yGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define the source and destination paths\n",
        "source_folder = \"/content/'Skimlit_UniversalModel\"\n",
        "destination_folder = \"'/content/drive/MyDrive/Colab Notebooks/Final Project Skill Academy/Skimlit_UniversalModel'\"\n",
        "\n",
        "# Copy the folder recursively\n",
        "shutil.copytree(source_folder, destination_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ECGgFLqWiLYL",
        "outputId": "3069f64c-0d44-498d-d08e-2f80b1c6a65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/destination_folder'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# loaded_model = tf.keras.models.load_model('/content/Skimlit_UniversalModel')\n",
        "loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/Final Project Skill Academy/Skimlit_UniversalModel')"
      ],
      "metadata": {
        "id": "mm6CUqiM8yvf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# Load your trained model\n",
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/Final Project Skill Academy/Skimlit_UniversalModel\")\n",
        "\n",
        "# Save the model to H5 format\n",
        "model.save('model.hdf5')\n",
        "\n",
        "print(\"Model successfully saved in hdf5 format!\")"
      ],
      "metadata": {
        "id": "bUkYrP1dJOTf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d10830b-84de-4009-cca2-b7b63734c47d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model successfully saved in hdf5 format!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Example Prediction"
      ],
      "metadata": {
        "id": "GaO4h8QjLM9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS']"
      ],
      "metadata": {
        "id": "j3QUGjQCT699"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "abstract = '''The problems lies not in spite of the sanitary residence neighborhood into a place or source of\n",
        "sanitation issues. The sanitation problems as the density of larvae that are in the environment around the\n",
        "house. The aim of this study was to analyze association between housing sanitation with the axistence of\n",
        "Aedes sp. larvae in working area of Public Health Center of Kutaraya, Kayu Agung. This study used a cross-sectional design, this study population was a entire house or building which\n",
        "is located in Public Health Center of Kutaraya. The sample amounted to 101 homes and buildings\n",
        "calculated with formula hypothesis test two proportions. Sampling by cluster random sampling technique.\n",
        "The collecting data used questionnaires and checklist. Data analysis was univariate, bivariate analysis using\n",
        "chi square test and Fisher Exact. Data analysis was perfomend by bivariate was a correlation between the presence of second-hand\n",
        "goods with larvae density ρ-value (0.001), the presence of water tanks/containers with larvae density by ρ\n",
        "value (0.000) and there was a correlation between the presence of clothing hanging at a density larvae Aedes\n",
        "sp. with ρ-value (0.002). DF value at level 6 and 7, HI 43% and BI 72%. Variables related to the density of larvae Aedes sp. namely the existence of thrift, the presence\n",
        "of water tanks/containers and the existence of clothes hanging. We recommend  to research include keeping\n",
        "and attention environmental sanitation in order to avoid transmitting dengue mosquito breeding sites so as to\n",
        "reduce the number population mosquitoes.'''\n",
        "# Create sentencizer - Source: https://spacy.io/usage/linguistic-features#sbd\n",
        "from spacy.lang.en import English\n",
        "nlp = English() # setup English sentence parser\n",
        "\n",
        "# New version of spaCy\n",
        "sentencizer = nlp.add_pipe(\"sentencizer\") # create sentence splitting pipeline object\n",
        "\n",
        "# Old version of spaCy\n",
        "# sentencizer = nlp.create_pipe(\"sentencizer\") # create sentence splitting pipeline object\n",
        "# nlp.add_pipe(sentencizer) # add sentence splitting pipeline object to sentence parser\n",
        "\n",
        "# Create \"doc\" of parsed sequences, change index for a different abstract\n",
        "doc = nlp(abstract)\n",
        "abstract_lines = [str(sent) for sent in list(doc.sents)] # return detected sentences from doc in string type (not spaCy token type)\n",
        "abstract_lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIo4_cD1X-Rm",
        "outputId": "f448df35-431c-42d5-e995-0a0bb09ecbba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The problems lies not in spite of the sanitary residence neighborhood into a place or source of\\nsanitation issues.',\n",
              " 'The sanitation problems as the density of larvae that are in the environment around the\\nhouse.',\n",
              " 'The aim of this study was to analyze association between housing sanitation with the axistence of\\nAedes sp.',\n",
              " 'larvae in working area of Public Health Center of Kutaraya, Kayu Agung.',\n",
              " 'This study used a cross-sectional design, this study population was a entire house or building which\\nis located in Public Health Center of Kutaraya.',\n",
              " 'The sample amounted to 101 homes and buildings\\ncalculated with formula hypothesis test two proportions.',\n",
              " 'Sampling by cluster random sampling technique.',\n",
              " '\\nThe collecting data used questionnaires and checklist.',\n",
              " 'Data analysis was univariate, bivariate analysis using\\nchi square test and Fisher Exact.',\n",
              " 'Data analysis was perfomend by bivariate was a correlation between the presence of second-hand\\ngoods with larvae density ρ-value (0.001), the presence of water tanks/containers with larvae density by ρ\\nvalue (0.000) and there was a correlation between the presence of clothing hanging at a density larvae Aedes\\nsp.',\n",
              " 'with ρ-value (0.002).',\n",
              " 'DF value at level 6 and 7, HI 43% and BI 72%.',\n",
              " 'Variables related to the density of larvae Aedes sp.',\n",
              " 'namely the existence of thrift, the presence\\nof water tanks/containers and the existence of clothes hanging.',\n",
              " 'We recommend  to research include keeping\\nand attention environmental sanitation in order to avoid transmitting dengue mosquito breeding sites so as to\\nreduce the number population mosquitoes.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get total number of lines\n",
        "total_lines_in_sample = len(abstract_lines)\n",
        "\n",
        "# Go through each line in abstract and create a list of dictionaries containing features for each line\n",
        "sample_lines = []\n",
        "for i, line in enumerate(abstract_lines):\n",
        "  sample_dict = {}\n",
        "  sample_dict[\"text\"] = str(line)\n",
        "  sample_dict[\"line_number\"] = i\n",
        "  sample_dict[\"total_lines\"] = total_lines_in_sample - 1\n",
        "  sample_lines.append(sample_dict)\n",
        "sample_lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiPijoMYYKtb",
        "outputId": "3ef374cb-d782-4ae4-937e-c1b6d01a7043"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'The problems lies not in spite of the sanitary residence neighborhood into a place or source of\\nsanitation issues.',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 14},\n",
              " {'text': 'The sanitation problems as the density of larvae that are in the environment around the\\nhouse.',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 14},\n",
              " {'text': 'The aim of this study was to analyze association between housing sanitation with the axistence of\\nAedes sp.',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 14},\n",
              " {'text': 'larvae in working area of Public Health Center of Kutaraya, Kayu Agung.',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 14},\n",
              " {'text': 'This study used a cross-sectional design, this study population was a entire house or building which\\nis located in Public Health Center of Kutaraya.',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 14},\n",
              " {'text': 'The sample amounted to 101 homes and buildings\\ncalculated with formula hypothesis test two proportions.',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 14},\n",
              " {'text': 'Sampling by cluster random sampling technique.',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 14},\n",
              " {'text': '\\nThe collecting data used questionnaires and checklist.',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 14},\n",
              " {'text': 'Data analysis was univariate, bivariate analysis using\\nchi square test and Fisher Exact.',\n",
              "  'line_number': 8,\n",
              "  'total_lines': 14},\n",
              " {'text': 'Data analysis was perfomend by bivariate was a correlation between the presence of second-hand\\ngoods with larvae density ρ-value (0.001), the presence of water tanks/containers with larvae density by ρ\\nvalue (0.000) and there was a correlation between the presence of clothing hanging at a density larvae Aedes\\nsp.',\n",
              "  'line_number': 9,\n",
              "  'total_lines': 14},\n",
              " {'text': 'with ρ-value (0.002).', 'line_number': 10, 'total_lines': 14},\n",
              " {'text': 'DF value at level 6 and 7, HI 43% and BI 72%.',\n",
              "  'line_number': 11,\n",
              "  'total_lines': 14},\n",
              " {'text': 'Variables related to the density of larvae Aedes sp.',\n",
              "  'line_number': 12,\n",
              "  'total_lines': 14},\n",
              " {'text': 'namely the existence of thrift, the presence\\nof water tanks/containers and the existence of clothes hanging.',\n",
              "  'line_number': 13,\n",
              "  'total_lines': 14},\n",
              " {'text': 'We recommend  to research include keeping\\nand attention environmental sanitation in order to avoid transmitting dengue mosquito breeding sites so as to\\nreduce the number population mosquitoes.',\n",
              "  'line_number': 14,\n",
              "  'total_lines': 14}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on sample abstract features\n",
        "test_abstract_pred_probs = loaded_model.predict(x=( tf.constant(abstract_lines)))\n",
        "test_abstract_pred_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgo0xvGOYSAo",
        "outputId": "ea451b34-c45e-4bd6-f16e-d413635215e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.31091690e-01, 1.08065039e-01, 5.94599508e-02, 1.25185579e-01,\n",
              "        1.76197708e-01],\n",
              "       [6.50381625e-01, 9.06736627e-02, 3.21984589e-02, 1.10513017e-01,\n",
              "        1.16233259e-01],\n",
              "       [3.43630910e-01, 3.86127383e-02, 2.07298175e-01, 3.68789405e-01,\n",
              "        4.16687727e-02],\n",
              "       [2.25890175e-01, 8.20162743e-02, 4.50805873e-01, 3.82897481e-02,\n",
              "        2.02997774e-01],\n",
              "       [4.69326600e-02, 2.53472254e-02, 8.18877757e-01, 1.63396131e-02,\n",
              "        9.25027430e-02],\n",
              "       [2.31659054e-04, 5.64265298e-04, 9.33862507e-01, 2.87126109e-04,\n",
              "        6.50543496e-02],\n",
              "       [4.78386573e-05, 9.06176429e-05, 9.85402048e-01, 5.52145539e-05,\n",
              "        1.44041553e-02],\n",
              "       [2.73604353e-04, 7.89928483e-04, 9.90450382e-01, 2.22670540e-04,\n",
              "        8.26325081e-03],\n",
              "       [4.06157720e-04, 7.78236252e-04, 8.65751624e-01, 3.30014358e-04,\n",
              "        1.32733911e-01],\n",
              "       [1.27563113e-02, 5.02584986e-02, 5.32784872e-02, 5.66754118e-03,\n",
              "        8.78039181e-01],\n",
              "       [1.19071640e-01, 1.95463330e-01, 1.62664846e-01, 4.37967405e-02,\n",
              "        4.79003489e-01],\n",
              "       [3.37911188e-05, 3.01370339e-04, 4.29233462e-01, 1.93412561e-05,\n",
              "        5.70412040e-01],\n",
              "       [7.84757137e-02, 5.74350841e-02, 1.25197619e-01, 2.19166875e-02,\n",
              "        7.16974914e-01],\n",
              "       [1.05403416e-01, 9.60271508e-02, 2.12347940e-01, 4.13610786e-02,\n",
              "        5.44860423e-01],\n",
              "       [4.14890617e-01, 4.99852866e-01, 5.78183960e-03, 6.03806935e-02,\n",
              "        1.90939885e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into prediction classes\n",
        "test_abstract_preds = tf.argmax(test_abstract_pred_probs, axis=1)\n",
        "test_abstract_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCirmGPQYial",
        "outputId": "0df22623-d977-44c8-ca98-ec75f306e16f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(15,), dtype=int64, numpy=array([0, 0, 3, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction class integers into string class names\n",
        "test_abstract_pred_classes = [classes[i] for i in test_abstract_preds]\n",
        "test_abstract_pred_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJrc0FFDYi0q",
        "outputId": "5396e5bf-11c6-493f-ad57-b23fa844dee7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BACKGROUND',\n",
              " 'BACKGROUND',\n",
              " 'OBJECTIVE',\n",
              " 'METHODS',\n",
              " 'METHODS',\n",
              " 'METHODS',\n",
              " 'METHODS',\n",
              " 'METHODS',\n",
              " 'METHODS',\n",
              " 'RESULTS',\n",
              " 'RESULTS',\n",
              " 'RESULTS',\n",
              " 'RESULTS',\n",
              " 'RESULTS',\n",
              " 'CONCLUSIONS']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize abstract lines and predicted sequence labels\n",
        "for i, line in enumerate(abstract_lines):\n",
        "  print(f\"{test_abstract_pred_classes[i]}: {line}\")"
      ],
      "metadata": {
        "id": "jFDTKA5RZVuM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d25a8343-b1fa-476b-ce55-6cace073b922"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BACKGROUND: The problems lies not in spite of the sanitary residence neighborhood into a place or source of\n",
            "sanitation issues.\n",
            "BACKGROUND: The sanitation problems as the density of larvae that are in the environment around the\n",
            "house.\n",
            "OBJECTIVE: The aim of this study was to analyze association between housing sanitation with the axistence of\n",
            "Aedes sp.\n",
            "METHODS: larvae in working area of Public Health Center of Kutaraya, Kayu Agung.\n",
            "METHODS: This study used a cross-sectional design, this study population was a entire house or building which\n",
            "is located in Public Health Center of Kutaraya.\n",
            "METHODS: The sample amounted to 101 homes and buildings\n",
            "calculated with formula hypothesis test two proportions.\n",
            "METHODS: Sampling by cluster random sampling technique.\n",
            "METHODS: \n",
            "The collecting data used questionnaires and checklist.\n",
            "METHODS: Data analysis was univariate, bivariate analysis using\n",
            "chi square test and Fisher Exact.\n",
            "RESULTS: Data analysis was perfomend by bivariate was a correlation between the presence of second-hand\n",
            "goods with larvae density ρ-value (0.001), the presence of water tanks/containers with larvae density by ρ\n",
            "value (0.000) and there was a correlation between the presence of clothing hanging at a density larvae Aedes\n",
            "sp.\n",
            "RESULTS: with ρ-value (0.002).\n",
            "RESULTS: DF value at level 6 and 7, HI 43% and BI 72%.\n",
            "RESULTS: Variables related to the density of larvae Aedes sp.\n",
            "RESULTS: namely the existence of thrift, the presence\n",
            "of water tanks/containers and the existence of clothes hanging.\n",
            "CONCLUSIONS: We recommend  to research include keeping\n",
            "and attention environmental sanitation in order to avoid transmitting dengue mosquito breeding sites so as to\n",
            "reduce the number population mosquitoes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "WN4aPsiiaIOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e50cf104-55d3-40bd-8da0-5cbbf5b09218"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.22.0-py3-none-any.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.13.0 (from gradio)\n",
            "  Downloading gradio_client-0.13.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.3.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.6.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.3.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.10.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.13.0->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.13.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.16.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.1)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=ff628b73553ac0624fe213281d7efc6be424c611a429d5e915a8a8a7050bf1d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, h11, colorama, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.2.1 colorama-0.4.6 fastapi-0.110.0 ffmpy-0.3.2 gradio-4.22.0 gradio-client-0.13.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 orjson-3.9.15 pydub-0.25.1 python-multipart-0.0.9 ruff-0.3.3 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.36.3 tomlkit-0.12.0 uvicorn-0.29.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from spacy.lang.en import English\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load your pre-trained model\n",
        "\n",
        "# Define a function to process input text and make predictions\n",
        "def predict_abstract(abstract):\n",
        "    classes = ['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS']\n",
        "    nlp = English()\n",
        "    sentencizer = nlp.add_pipe(\"sentencizer\") # create sentence splitting pipeline object\n",
        "    doc = nlp(abstract)\n",
        "    abstract_lines = [str(sent) for sent in list(doc.sents)]\n",
        "    total_lines_in_sample = len(abstract_lines)\n",
        "    sample_lines = []\n",
        "    for i, line in enumerate(abstract_lines):\n",
        "        sample_dict = {}\n",
        "        sample_dict[\"text\"] = str(line)\n",
        "        sample_dict[\"line_number\"] = i\n",
        "        sample_dict[\"total_lines\"] = total_lines_in_sample - 1\n",
        "        sample_lines.append(sample_dict)\n",
        "    test_abstract_pred_probs = loaded_model.predict(x=( tf.constant(abstract_lines)))\n",
        "    test_abstract_preds = tf.argmax(test_abstract_pred_probs, axis=1)\n",
        "    test_abstract_preds = tf.argmax(test_abstract_pred_probs, axis=1)\n",
        "    test_abstract_pred_classes = [classes[i] for i in test_abstract_preds]\n",
        "    # Combine predicted classes with abstract lines\n",
        "    results = \"\"\n",
        "    for class_name, line in zip(test_abstract_pred_classes, abstract_lines):\n",
        "        results += f\"{class_name}: {line}\\n\"\n",
        "    return results\n",
        "\n",
        "\n",
        "# Create Gradio interface\n",
        "input_text = gr.Textbox(label=\"Input Abstract\")\n",
        "output_text = gr.Textbox(label=\"Predicted Label\")\n",
        "\n",
        "gr.Interface(fn=predict_abstract, inputs=input_text, outputs=output_text, title=\"Abstract Classifier\").launch()\n",
        "\n"
      ],
      "metadata": {
        "id": "C3N6XelQZLga",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "56db2b96-3fc1-4c1c-bda8-893caa7b2a3a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://d2e9ef9808579eefec.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d2e9ef9808579eefec.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ced6b581-708f-4758-86ff-3cd51bf14f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8570106a-7037-4d0b-dc64-17b14772ad33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Assignment successfully submitted'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "portfolio_link = \"https://drive.google.com/drive/folders/1SivWOzuU9L3pf7iLjeCxVr7-of27w0IN?usp=sharing\"\n",
        "presentation_link = \"https://drive.google.com/drive/folders/1K-2JsOY8mpfyh3XLCappJTB8T5cako14?usp=sharing\"\n",
        "\n",
        "question_id = \"01_portfolio_link\"\n",
        "submit(student_id, name, assignment_id, str(portfolio_link), question_id, drive_link)\n",
        "\n",
        "question_id = \"02_presentation_link\"\n",
        "submit(student_id, name, assignment_id, str(presentation_link), question_id, drive_link)"
      ]
    }
  ]
}